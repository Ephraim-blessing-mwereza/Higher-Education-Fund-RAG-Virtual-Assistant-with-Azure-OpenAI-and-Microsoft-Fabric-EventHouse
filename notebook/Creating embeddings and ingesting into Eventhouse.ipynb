{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ad43d75-6a42-4b60-9338-1bbc4dd49732",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Building a RAG  HEF Assistant with Fabric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17d61d8e-d4ec-4815-ba89-f1fc28ff69b1",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-07T13:27:11.0800947Z",
       "execution_start_time": "2025-04-07T13:26:13.4757063Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "027b94a4-2e06-4d4e-9d60-03422a074a5b",
       "queued_time": "2025-04-07T13:26:08.5741243Z",
       "session_id": "9bc2ccbb-73b6-4883-b6fa-6375be8dd600",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 8,
       "statement_ids": [
        3,
        4,
        5,
        6,
        7,
        8
       ]
      },
      "text/plain": [
       "StatementMeta(, 9bc2ccbb-73b6-4883-b6fa-6375be8dd600, 8, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==1.12.0\n",
      "  Downloading openai-1.12.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting azure-kusto-data\n",
      "  Downloading azure_kusto_data-5.0.2-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: tenacity in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (8.2.3)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.12-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from openai==1.12.0) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from openai==1.12.0) (1.8.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai==1.12.0)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai==1.12.0)\n",
      "  Downloading pydantic-2.11.2-py3-none-any.whl.metadata (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m998.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from openai==1.12.0) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from openai==1.12.0) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from openai==1.12.0) (4.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from azure-kusto-data) (2.8.2)\n",
      "Collecting requests>=2.32.3 (from azure-kusto-data)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting azure-identity<2,>=1.21.0 (from azure-kusto-data)\n",
      "  Downloading azure_identity-1.21.0-py3-none-any.whl.metadata (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: msal<2,>=1.9.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from azure-kusto-data) (1.25.0)\n",
      "Collecting ijson~=3.1 (from azure-kusto-data)\n",
      "  Downloading ijson-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: azure-core<2,>=1.11.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from azure-kusto-data) (1.30.2)\n",
      "Collecting langchain-core<1.0.0,>=0.3.51 (from langchain)\n",
      "  Downloading langchain_core-0.3.51-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.24-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.11-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.10-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.9-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.7-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.6-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_openai-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.3-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.3.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.3.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.3.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.2.13-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.2.10-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.9-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.8-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.7-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.6-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.3-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.25-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.24-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.23-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.22-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.20-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.19-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.17-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.16-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.15-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.14-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.13-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.11-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.10-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.6-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.3-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.0.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.0.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.0.6-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.0.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.0.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.0.3-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.0.2.post1-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading langchain_openai-0.0.2-py3-none-any.whl.metadata (570 bytes)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.22-py3-none-any.whl.metadata (7.8 kB)\n",
      "  Downloading langchain-0.3.21-py3-none-any.whl.metadata (7.8 kB)\n",
      "  Downloading langchain-0.3.20-py3-none-any.whl.metadata (7.7 kB)\n",
      "  Downloading langchain-0.3.19-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: numpy<2,>=1.26.4 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "  Downloading langchain-0.3.18-py3-none-any.whl.metadata (7.8 kB)\n",
      "  Downloading langchain-0.3.17-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.16-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.15-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langsmith<0.3,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.2.11-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.13-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.12-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.11-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.10-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.9-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.8-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.6-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.5-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.4-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.2.17-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-core<0.3.0,>=0.2.43 (from langchain)\n",
      "  Downloading langchain_core-0.2.43-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.2.16-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.2.15-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.2.14-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.2.13-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.2.12-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.2.11-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.2.10-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Downloading langchain-0.2.9-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Downloading langchain-0.2.8-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Downloading langchain-0.2.7-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Downloading langchain-0.2.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading langchain-0.2.5-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading langchain-0.2.4-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading langchain-0.2.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Downloading langchain-0.2.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langchain-0.2.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langchain-0.2.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.1.20-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.38 (from langchain)\n",
      "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.52 (from langchain)\n",
      "  Downloading langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting tiktoken<1,>=0.5.2 (from langchain-openai)\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.52->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.52->langchain)\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: idna>=2.8 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai==1.12.0) (3.4)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from azure-core<2,>=1.11.0->azure-kusto-data) (1.16.0)\n",
      "Collecting azure-core<2,>=1.11.0 (from azure-kusto-data)\n",
      "  Downloading azure_core-1.33.0-py3-none-any.whl.metadata (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cryptography>=2.5 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from azure-identity<2,>=1.21.0->azure-kusto-data) (42.0.2)\n",
      "Collecting msal<2,>=1.9.0 (from azure-kusto-data)\n",
      "  Downloading msal-1.32.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal-extensions>=1.2.0 (from azure-identity<2,>=1.21.0->azure-kusto-data)\n",
      "  Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: certifi in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai==1.12.0) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.12.0)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.12.0)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal<2,>=1.9.0->azure-kusto-data) (2.4.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai==1.12.0)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic<3,>=1.9.0->openai==1.12.0)\n",
      "  Downloading pydantic_core-2.33.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-extensions<5,>=4.7 (from openai==1.12.0)\n",
      "  Downloading typing_extensions-4.13.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai==1.12.0)\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from requests>=2.32.3->azure-kusto-data) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from requests>=2.32.3->azure-kusto-data) (2.1.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.10.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from cryptography>=2.5->azure-identity<2,>=1.21.0->azure-kusto-data) (1.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain) (2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: pycparser in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity<2,>=1.21.0->azure-kusto-data) (2.21)\n",
      "Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading azure_kusto_data-5.0.2-py2.py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.2/52.2 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.1.5-py3-none-any.whl (34 kB)\n",
      "Downloading langchain_core-0.1.53-py3-none-any.whl (303 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.1/303.1 kB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_identity-1.21.0-py3-none-any.whl (189 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.2/189.2 kB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_core-1.33.0-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.1/207.1 kB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ijson-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (119 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.2/119.2 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
      "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msal-1.32.0-py3-none-any.whl (114 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.11.2-py3-none-any.whl (443 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.3/443.3 kB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.33.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m131.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.13.1-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
      "Downloading orjson-3.10.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ijson, typing-extensions, requests, pypdf, packaging, orjson, jsonpatch, h11, annotated-types, typing-inspection, typing-inspect, tiktoken, requests-toolbelt, pydantic-core, marshmallow, httpcore, azure-core, pydantic, httpx, dataclasses-json, openai, msal, langsmith, msal-extensions, langchain-core, langchain-text-splitters, langchain-openai, langchain-community, azure-identity, langchain, azure-kusto-data\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.9.0\n",
      "    Not uninstalling typing-extensions at /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages, outside environment /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1\n",
      "    Can't uninstall 'typing_extensions'. No files were found to uninstall.\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Not uninstalling requests at /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages, outside environment /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1\n",
      "    Can't uninstall 'requests'. No files were found to uninstall.\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Not uninstalling packaging at /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages, outside environment /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1\n",
      "    Can't uninstall 'packaging'. No files were found to uninstall.\n",
      "  Attempting uninstall: jsonpatch\n",
      "    Found existing installation: jsonpatch 1.32\n",
      "    Not uninstalling jsonpatch at /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages, outside environment /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1\n",
      "    Can't uninstall 'jsonpatch'. No files were found to uninstall.\n",
      "  Attempting uninstall: azure-core\n",
      "    Found existing installation: azure-core 1.30.2\n",
      "    Not uninstalling azure-core at /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages, outside environment /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1\n",
      "    Can't uninstall 'azure-core'. No files were found to uninstall.\n",
      "  Attempting uninstall: msal\n",
      "    Found existing installation: msal 1.25.0\n",
      "    Not uninstalling msal at /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages, outside environment /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1\n",
      "    Can't uninstall 'msal'. No files were found to uninstall.\n",
      "  Attempting uninstall: msal-extensions\n",
      "    Found existing installation: msal-extensions 1.0.0\n",
      "    Not uninstalling msal-extensions at /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages, outside environment /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1\n",
      "    Can't uninstall 'msal-extensions'. No files were found to uninstall.\n",
      "  Attempting uninstall: azure-identity\n",
      "    Found existing installation: azure-identity 1.15.0\n",
      "    Not uninstalling azure-identity at /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages, outside environment /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1\n",
      "    Can't uninstall 'azure-identity'. No files were found to uninstall.\n",
      "Successfully installed annotated-types-0.7.0 azure-core-1.33.0 azure-identity-1.21.0 azure-kusto-data-5.0.2 dataclasses-json-0.6.7 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 ijson-3.3.0 jsonpatch-1.33 langchain-0.1.20 langchain-community-0.0.38 langchain-core-0.1.53 langchain-openai-0.1.5 langchain-text-splitters-0.0.2 langsmith-0.1.147 marshmallow-3.26.1 msal-1.32.0 msal-extensions-1.3.1 openai-1.12.0 orjson-3.10.16 packaging-23.2 pydantic-2.11.2 pydantic-core-2.33.1 pypdf-5.4.0 requests-2.32.3 requests-toolbelt-1.0.0 tiktoken-0.9.0 typing-extensions-4.13.1 typing-inspect-0.9.0 typing-inspection-0.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: beautifulsoup4 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: langchain-community in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (0.0.38)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from langchain-community) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from langchain-community) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from langchain-community) (0.1.53)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from langchain-community) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from langchain-community) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.52->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.52->langchain-community) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.52->langchain-community) (2.11.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (2024.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.13.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.1)\n",
      "Requirement already satisfied: anyio in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain-community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.52->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.52->langchain-community) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.52->langchain-community) (0.4.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Warning: PySpark kernel has been restarted to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install openai==1.12.0 azure-kusto-data langchain tenacity langchain-openai pypdf\n",
    "%pip install beautifulsoup4 langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c29c4b81-d65a-4c51-b58c-593975d23edf",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-07T13:27:27.287318Z",
       "execution_start_time": "2025-04-07T13:27:16.654857Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "c25c4570-dc27-49c1-8619-9ef2c3a09df7",
       "queued_time": "2025-04-07T13:27:16.6544047Z",
       "session_id": "9bc2ccbb-73b6-4883-b6fa-6375be8dd600",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 14,
       "statement_ids": [
        10,
        11,
        12,
        13,
        14
       ]
      },
      "text/plain": [
       "StatementMeta(, 9bc2ccbb-73b6-4883-b6fa-6375be8dd600, 14, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (1.12.0)\n",
      "Collecting openai\n",
      "  Downloading openai-1.70.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from openai) (2.11.2)\n",
      "Requirement already satisfied: sniffio in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from openai) (4.13.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /nfs4/pyenv-339e0149-dd28-4e9a-a5f3-3f68ae03acb1/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Downloading openai-1.70.0-py3-none-any.whl (599 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.1/599.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (351 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m351.8/351.8 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jiter, openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.12.0\n",
      "    Uninstalling openai-1.12.0:\n",
      "      Successfully uninstalled openai-1.12.0\n",
      "Successfully installed jiter-0.9.0 openai-1.70.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Warning: PySpark kernel has been restarted to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install openai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00b8ee10-45c5-4f3d-9d8a-e929c863cd27",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-07T13:28:08.9258544Z",
       "execution_start_time": "2025-04-07T13:28:06.6486306Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "76227e66-33b7-4dc6-8680-7c12e9b6b976",
       "queued_time": "2025-04-07T13:28:01.7162973Z",
       "session_id": "9bc2ccbb-73b6-4883-b6fa-6375be8dd600",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 16,
       "statement_ids": [
        16
       ]
      },
      "text/plain": [
       "StatementMeta(, 9bc2ccbb-73b6-4883-b6fa-6375be8dd600, 16, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "import textwrap\n",
    "import json \n",
    "import requests\n",
    "import pandas as pd\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "from notebookutils import mssparkutils\n",
    "from azure.kusto.data import KustoClient, KustoConnectionStringBuilder\n",
    "from azure.kusto.data.exceptions import KustoServiceError\n",
    "from azure.kusto.data.helpers import dataframe_from_result_table\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter,RecursiveCharacterTextSplitter\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from bs4 import SoupStrainer\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98e7982-0606-4a3d-8a06-268f5ac792ff",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-07T13:28:14.4592262Z",
       "execution_start_time": "2025-04-07T13:28:13.6902577Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "d940900e-af75-40be-9cb4-d111b5664b07",
       "queued_time": "2025-04-07T13:28:13.6891154Z",
       "session_id": "9bc2ccbb-73b6-4883-b6fa-6375be8dd600",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 17,
       "statement_ids": [
        17
       ]
      },
      "text/plain": [
       "StatementMeta(, 9bc2ccbb-73b6-4883-b6fa-6375be8dd600, 17, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OPENAI_GPT4_DEPLOYMENT_NAME=\"gpt-4o-kenya-hack\"\n",
    "OPENAI_DEPLOYMENT_ENDPOINT=\"Your-OpenAI-Endpoint\" # Replace with your OpenAI endpoint\n",
    "OPENAI_API_KEY=\"Your-OpenAI-API-KEY\" # Replace with your OpenAI API key\n",
    "OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME = \"text-embedding-ada-002-kenya-hack\"\n",
    "\n",
    "\n",
    "KUSTO_URI = 'Your-Kusto-URI' # Replace with your kusto URI\n",
    "KUSTO_DATABASE = \"HEF_eventhouse\"\n",
    "KUSTO_TABLE = \"hefEmbeddings\"\n",
    "accessToken = mssparkutils.credentials.getToken(KUSTO_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fac1fe1-71ed-4fd8-82bf-33cf0d867170",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Creating an Azure OpenAI client and defining a function to calculate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa49e866-7f4e-41f6-a561-b11833309559",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-07T13:28:23.7286499Z",
       "execution_start_time": "2025-04-07T13:28:23.4513712Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "e0991374-2d21-4f9b-b9c6-227cfaced9fb",
       "queued_time": "2025-04-07T13:28:23.4501535Z",
       "session_id": "9bc2ccbb-73b6-4883-b6fa-6375be8dd600",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 18,
       "statement_ids": [
        18
       ]
      },
      "text/plain": [
       "StatementMeta(, 9bc2ccbb-73b6-4883-b6fa-6375be8dd600, 18, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client = AzureOpenAI(\n",
    "        azure_endpoint=OPENAI_DEPLOYMENT_ENDPOINT,\n",
    "        api_key=OPENAI_API_KEY,\n",
    "        api_version=\"2023-09-01-preview\"\n",
    "    )\n",
    "\n",
    "#we use the tenacity library to create delays and retries when calling openAI embeddings to avoid hitting throttling limits\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def generate_embeddings(text): \n",
    "    # replace newlines, which can negatively affect performance.\n",
    "    txt = text.replace(\"\\n\", \" \")\n",
    "    return client.embeddings.create(input = [txt], model=OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME).data[0].embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776e0e76-65af-4d1a-9568-48076c6ea709",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Reading the pdf files, divide it into 1000 chars chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb964d3c-fa39-44f3-9e75-cb65d9dcc573",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-07T13:28:29.954743Z",
       "execution_start_time": "2025-04-07T13:28:29.6237863Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "ec7c5274-0aeb-41d9-8dc9-b8e69713a19a",
       "queued_time": "2025-04-07T13:28:29.6226306Z",
       "session_id": "9bc2ccbb-73b6-4883-b6fa-6375be8dd600",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 19,
       "statement_ids": [
        19
       ]
      },
      "text/plain": [
       "StatementMeta(, 9bc2ccbb-73b6-4883-b6fa-6375be8dd600, 19, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# splitting into 1000 char long chunks with 30 char overlap\n",
    "# split [\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=30,\n",
    ")\n",
    "\n",
    "# List of PDF files (adjust filenames as per your lakehouse)\n",
    "pdf_files = [\n",
    "    {\"name\": \"UF-FAQs.pdf\", \"path\": \"/lakehouse/default/Files/UF-FAQs.pdf\"},\n",
    "    {\"name\": \"HEF-NFM-FAQs.pdf\", \"path\": \"/lakehouse/default/Files/HEF-NFM-FAQs.pdf\"},  \n",
    "    {\"name\": \"Helb-FAQS.pdf\", \"path\": \"/lakehouse/default/Files/Helb-FAQS.pdf\"}, \n",
    "    {\"name\": \"University-Funding-FAQs2.pdf\", \"path\": \"/lakehouse/default/Files/University-Funding-FAQs2.pdf\"},\n",
    "]\n",
    "\n",
    "# List of web URLs\n",
    "web_urls = [\n",
    "    \"https://www.helb.co.ke/faqs/students-faqs/\",\n",
    "    \"https://www.helb.co.ke/faqs/loanees-faqs/\",\n",
    "    \"https://www.helb.co.ke/faqs/employers-faqs/\",\n",
    "    \"https://www.helb.co.ke/faqs/institutions-faqs/\",\n",
    "    \"https://www.hef.co.ke/\",\n",
    "    \"https://www.hef.co.ke/faqs/\",\n",
    "    \"https://kuccps.net/frequently-asked-questions\",\n",
    "    \"https://www.universitiesfund.go.ke/blog/frequently-asked-questions/\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bf90b1e-6a8d-48f9-8266-e0ffd802c70f",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-07T13:28:42.6830716Z",
       "execution_start_time": "2025-04-07T13:28:41.21375Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "e3682584-1a97-499e-bb42-ba127f9b2970",
       "queued_time": "2025-04-07T13:28:41.2126403Z",
       "session_id": "9bc2ccbb-73b6-4883-b6fa-6375be8dd600",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 20,
       "statement_ids": [
        20
       ]
      },
      "text/plain": [
       "StatementMeta(, 9bc2ccbb-73b6-4883-b6fa-6375be8dd600, 20, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7 chunks from UF-FAQs.pdf\n",
      "Loaded 8 chunks from HEF-NFM-FAQs.pdf\n",
      "Loaded 12 chunks from Helb-FAQS.pdf\n",
      "Loaded 19 chunks from University-Funding-FAQs2.pdf\n"
     ]
    }
   ],
   "source": [
    "# Load PDFs\n",
    "all_pages = []\n",
    "for pdf in pdf_files:\n",
    "    try:\n",
    "        loader = PyPDFLoader(pdf[\"path\"])\n",
    "        pages = loader.load_and_split(text_splitter=splitter)\n",
    "        print(f\"Loaded {len(pages)} chunks from {pdf['name']}\")\n",
    "        all_pages.extend(pages)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {pdf['name']}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ee0fe9f-b7cc-4fa8-a01e-201dc8799583",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-07T13:29:52.2580972Z",
       "execution_start_time": "2025-04-07T13:29:07.9754167Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "e0603d51-98ac-464e-a29d-f643fc587ffa",
       "queued_time": "2025-04-07T13:29:07.9742043Z",
       "session_id": "9bc2ccbb-73b6-4883-b6fa-6375be8dd600",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 22,
       "statement_ids": [
        22
       ]
      },
      "text/plain": [
       "StatementMeta(, 9bc2ccbb-73b6-4883-b6fa-6375be8dd600, 22, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WebBaseLoader failed for https://www.helb.co.ke/faqs/students-faqs/: HTTPSConnectionPool(host='www.helb.co.ke', port=443): Max retries exceeded with url: /faqs/students-faqs/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "Fallback loaded 14 chunks from https://www.helb.co.ke/faqs/students-faqs/\n",
      "WebBaseLoader failed for https://www.helb.co.ke/faqs/loanees-faqs/: HTTPSConnectionPool(host='www.helb.co.ke', port=443): Max retries exceeded with url: /faqs/loanees-faqs/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "Fallback loaded 8 chunks from https://www.helb.co.ke/faqs/loanees-faqs/\n",
      "WebBaseLoader failed for https://www.helb.co.ke/faqs/employers-faqs/: HTTPSConnectionPool(host='www.helb.co.ke', port=443): Max retries exceeded with url: /faqs/employers-faqs/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "Fallback loaded 7 chunks from https://www.helb.co.ke/faqs/employers-faqs/\n",
      "WebBaseLoader failed for https://www.helb.co.ke/faqs/institutions-faqs/: HTTPSConnectionPool(host='www.helb.co.ke', port=443): Max retries exceeded with url: /faqs/institutions-faqs/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "Fallback loaded 6 chunks from https://www.helb.co.ke/faqs/institutions-faqs/\n",
      "Loaded 10 chunks from https://www.hef.co.ke/\n",
      "Loaded 15 chunks from https://www.hef.co.ke/faqs/\n",
      "Loaded 16 chunks from https://kuccps.net/frequently-asked-questions\n",
      "Loaded 13 chunks from https://www.universitiesfund.go.ke/blog/frequently-asked-questions/\n",
      "Total number of chunks:  135\n"
     ]
    }
   ],
   "source": [
    "# Load web content\n",
    "for url in web_urls:\n",
    "    try:\n",
    "        # Try WebBaseLoader with SSL verification disabled\n",
    "        loader = WebBaseLoader(url, verify_ssl=False)\n",
    "        pages = loader.load_and_split(text_splitter=splitter)\n",
    "        print(f\"Loaded {len(pages)} chunks from {url}\")\n",
    "        all_pages.extend(pages)\n",
    "    except Exception as e:\n",
    "        print(f\"WebBaseLoader failed for {url}: {e}\")\n",
    "        # Fallback: Use requests directly\n",
    "        try:\n",
    "            response = requests.get(url, verify=False)  # Bypass SSL verification\n",
    "            response.raise_for_status()  # Check for HTTP errors\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            text = soup.get_text(separator=\" \")  # Extract all text\n",
    "            \n",
    "            # Create a single Document object manually\n",
    "            from langchain.docstore.document import Document\n",
    "            doc = Document(page_content=text, metadata={\"source\": url})\n",
    "            pages = splitter.split_documents([doc])\n",
    "            print(f\"Fallback loaded {len(pages)} chunks from {url}\")\n",
    "            all_pages.extend(pages)\n",
    "        except Exception as fallback_e:\n",
    "            print(f\"Fallback failed for {url}: {fallback_e}\")\n",
    "\n",
    "# Total chunks\n",
    "print(\"Total number of chunks: \", len(all_pages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfca7626-31e5-425f-8095-10b1ccefdf30",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Saving the text chunks to a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1803a4d6-73af-4758-ae50-9c4f74574208",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-07T13:29:59.0779898Z",
       "execution_start_time": "2025-04-07T13:29:58.3027555Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "82f90940-5658-4c39-ad3a-32e94a0dd118",
       "queued_time": "2025-04-07T13:29:58.3015455Z",
       "session_id": "9bc2ccbb-73b6-4883-b6fa-6375be8dd600",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 23,
       "statement_ids": [
        23
       ]
      },
      "text/plain": [
       "StatementMeta(, 9bc2ccbb-73b6-4883-b6fa-6375be8dd600, 23, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_name</th>\n",
       "      <th>content</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/lakehouse/default/Files/UF-FAQs.pdf</td>\n",
       "      <td>1. What is a Higher Education Government Stude...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/lakehouse/default/Files/UF-FAQs.pdf</td>\n",
       "      <td>• The scholarship application is currently ope...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/lakehouse/default/Files/UF-FAQs.pdf</td>\n",
       "      <td>and are placed by KUCCPS in a public universit...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/lakehouse/default/Files/UF-FAQs.pdf</td>\n",
       "      <td>6. How can I apply for a Government Student Sc...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/lakehouse/default/Files/UF-FAQs.pdf</td>\n",
       "      <td>8. How long can I qualify for the Government S...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          document_name  \\\n",
       "0  /lakehouse/default/Files/UF-FAQs.pdf   \n",
       "1  /lakehouse/default/Files/UF-FAQs.pdf   \n",
       "2  /lakehouse/default/Files/UF-FAQs.pdf   \n",
       "3  /lakehouse/default/Files/UF-FAQs.pdf   \n",
       "4  /lakehouse/default/Files/UF-FAQs.pdf   \n",
       "\n",
       "                                             content embedding  \n",
       "0  1. What is a Higher Education Government Stude...            \n",
       "1  • The scholarship application is currently ope...            \n",
       "2  and are placed by KUCCPS in a public universit...            \n",
       "3  6. How can I apply for a Government Student Sc...            \n",
       "4  8. How long can I qualify for the Government S...            "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save to DataFrame\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(columns=['document_name', 'content', 'embedding'])\n",
    "for page in all_pages:\n",
    "    # Use source (URL or file path) as document name\n",
    "    doc_name = page.metadata.get('source', 'Unknown PDF')\n",
    "    df.loc[len(df.index)] = [doc_name, page.page_content, \"\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06214cf1-66ae-44bc-adb0-6dd1549062d0",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Calculating embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57db0e60-91a0-41c6-8e70-2cd5e0235f78",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-07T13:31:08.6904627Z",
       "execution_start_time": "2025-04-07T13:30:11.7424273Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "69a9cbc0-fd9a-405d-b064-d8b8cf1c1265",
       "queued_time": "2025-04-07T13:30:11.7412685Z",
       "session_id": "9bc2ccbb-73b6-4883-b6fa-6375be8dd600",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 24,
       "statement_ids": [
        24
       ]
      },
      "text/plain": [
       "StatementMeta(, 9bc2ccbb-73b6-4883-b6fa-6375be8dd600, 24, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          document_name  \\\n",
      "0  /lakehouse/default/Files/UF-FAQs.pdf   \n",
      "1  /lakehouse/default/Files/UF-FAQs.pdf   \n",
      "\n",
      "                                             content  \\\n",
      "0  1. What is a Higher Education Government Stude...   \n",
      "1  • The scholarship application is currently ope...   \n",
      "\n",
      "                                           embedding  \n",
      "0  [0.024698741734027863, -0.0024227292742580175,...  \n",
      "1  [0.01745203323662281, 0.004714916460216045, 0....  \n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings (assuming generate_embeddings is defined)\n",
    "df[\"embedding\"] = df.content.apply(lambda x: generate_embeddings(x))\n",
    "print(df.head(2))\n",
    "\n",
    "# Optional: Save DataFrame to a file or database for later use\n",
    "# df.to_csv(\"/lakehouse/default/Files/combined_embeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75087c6-7838-4e88-b5a4-f2403dc2c6f9",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Writing the data to MS Fabric Eventhouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8086768",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-07T13:33:51.8777722Z",
       "execution_start_time": "2025-04-07T13:32:55.019279Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "eed9d6e6-ff83-47fb-be60-960180ba971c",
       "queued_time": "2025-04-07T13:32:55.0181669Z",
       "session_id": "9bc2ccbb-73b6-4883-b6fa-6375be8dd600",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 25,
       "statement_ids": [
        25
       ]
      },
      "text/plain": [
       "StatementMeta(, 9bc2ccbb-73b6-4883-b6fa-6375be8dd600, 25, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_sp = spark.createDataFrame(df)\n",
    "\n",
    "df_sp.write.\\\n",
    "format(\"com.microsoft.kusto.spark.synapse.datasource\").\\\n",
    "option(\"kustoCluster\",KUSTO_URI).\\\n",
    "option(\"kustoDatabase\",KUSTO_DATABASE).\\\n",
    "option(\"kustoTable\", KUSTO_TABLE).\\\n",
    "option(\"accessToken\", accessToken ).\\\n",
    "mode(\"Append\").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5be7384-5b76-4481-bc7c-1e6a504bf90b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Vector search on Fabric Eventhouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee864bae-b08d-4bdb-92ff-baa22a2c9ea7",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### A function to calling GPT4 for a Natural Language answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8c07e41-f19f-4141-9add-3e0a1ae2b4fc",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-07T13:35:19.5782595Z",
       "execution_start_time": "2025-04-07T13:35:19.29089Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "fdedb3ef-4a75-4bfc-8ac6-23aa36e7d0aa",
       "queued_time": "2025-04-07T13:35:19.2897469Z",
       "session_id": "9bc2ccbb-73b6-4883-b6fa-6375be8dd600",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 26,
       "statement_ids": [
        26
       ]
      },
      "text/plain": [
       "StatementMeta(, 9bc2ccbb-73b6-4883-b6fa-6375be8dd600, 26, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def call_openAI(text):\n",
    "    response = client.chat.completions.create(\n",
    "        model=OPENAI_GPT4_DEPLOYMENT_NAME,\n",
    "        messages = text,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de7a2ab-8d1b-49da-bdbb-e2b2c0a140a1",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#####  A function  retrieving answers using embeddings with similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77a1573c-b896-41ae-b9e9-cb04663ab1a4",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-07T13:35:26.7266522Z",
       "execution_start_time": "2025-04-07T13:35:26.431098Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "edbe8e4d-e1be-4888-aabb-94a5e8172337",
       "queued_time": "2025-04-07T13:35:26.429901Z",
       "session_id": "9bc2ccbb-73b6-4883-b6fa-6375be8dd600",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 27,
       "statement_ids": [
        27
       ]
      },
      "text/plain": [
       "StatementMeta(, 9bc2ccbb-73b6-4883-b6fa-6375be8dd600, 27, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_answer_from_eventhouse(question, nr_of_answers=1):\n",
    "        searchedEmbedding = generate_embeddings(question)\n",
    "        kusto_query = KUSTO_TABLE + \" | extend similarity = series_cosine_similarity(dynamic(\"+str(searchedEmbedding)+\"), embedding) | top \" + str(nr_of_answers) + \" by similarity desc \"\n",
    "        kustoDf  = spark.read\\\n",
    "        .format(\"com.microsoft.kusto.spark.synapse.datasource\")\\\n",
    "        .option(\"kustoCluster\",KUSTO_URI)\\\n",
    "        .option(\"kustoDatabase\",KUSTO_DATABASE)\\\n",
    "        .option(\"accessToken\", accessToken)\\\n",
    "        .option(\"kustoQuery\", kusto_query).load()\n",
    "\n",
    "        return kustoDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e03a79d5-c0fd-49e7-9871-d95b040bd395",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-04-07T13:35:39.696502Z",
       "execution_start_time": "2025-04-07T13:35:33.6050825Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "0e378fe8-0a41-4f5c-9879-5166ab626d2f",
       "queued_time": "2025-04-07T13:35:33.6037823Z",
       "session_id": "9bc2ccbb-73b6-4883-b6fa-6375be8dd600",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 28,
       "statement_ids": [
        28
       ]
      },
      "text/plain": [
       "StatementMeta(, 9bc2ccbb-73b6-4883-b6fa-6375be8dd600, 28, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'No, IGCSE graduates cannot apply to KUCCPS for placement to universities and colleges. KUCCPS placement is specifically for students who have completed the KCSE examination.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Retrieves 2 answers from Eventhouse\n",
    "nr_of_answers = 2\n",
    "question = \"Can IGCSE graduates apply to KUCCPS for placement to universities and colleges?\"\n",
    "answers_df = get_answer_from_eventhouse(question, nr_of_answers)\n",
    "\n",
    "# Concatenates the answers\n",
    "answer = \"\"\n",
    "for row in answers_df.rdd.toLocalIterator():\n",
    "    answer = answer + \" \" + row['content']\n",
    "\n",
    "# Creates a prompt for GPT4 with the question and the 2 answers\n",
    "prompt = 'Question: {}'.format(question) + '\\n' + 'Information: {}'.format(answer)\n",
    "# prepare prompt\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are a HELPFUL assistant answering users questions. Answer the question using the provided information and do not add anything else.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "result = call_openAI(messages)\n",
    "display(result)\n"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "20c0620b-e82e-4c71-a4ad-2dd2017ff944",
    "default_lakehouse_name": "Hef_Lakehouse",
    "default_lakehouse_workspace_id": "ec5a7aca-e27f-4992-80fd-e88ce676daca",
    "known_lakehouses": [
     {
      "id": "20c0620b-e82e-4c71-a4ad-2dd2017ff944"
     }
    ]
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "orig_nbformat": 4,
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
